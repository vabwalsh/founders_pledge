{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-carpet",
   "metadata": {},
   "source": [
    "### Cleaning Steel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in steel data with already corrected country names\n",
    "steel = pd.read_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/inputs_w_country_fix/steel_cntry_fix.csv', index_col = 0)\n",
    "\n",
    "# subset the steel data, only selecting the production columns so they can be filtered differently\n",
    "production_cols = []\n",
    "for col in steel.columns:\n",
    "    if 'capacity' in col:\n",
    "        production_cols.append(col)\n",
    "\n",
    "# select the relevant data columns, and clean them\n",
    "steel_subset = steel[['country.name.en', 'Region', 'Status', 'Start','Primary steelmaking process (integrated, electric, or oxygen)']].join(steel[production_cols])\n",
    "steel_subset[production_cols] = steel_subset[production_cols].replace(to_replace = [' ','unknown','>0',np.nan], value = 1)#.astype(float)\n",
    "steel_subset[production_cols] = steel_subset[production_cols].replace('10,000',10000).astype(float)\n",
    "  \n",
    "# filter the data for active plants only \n",
    "steel_oper = steel_subset[(steel_subset['Status'] == 'proposed') ^ (steel_subset['Status'] == 'operating') \n",
    "                          ^ (steel_subset['Status'] == 'construction') ^ (steel_subset['Status'] == 'unknown')]\n",
    "\n",
    "# reindex the df to retain standard integer indexing and prevent random index loss\n",
    "steel_indexed = steel_oper.reset_index(drop = 'index')\n",
    "\n",
    "# rename the data to be consistent with coal and gas data\n",
    "steel_clean = steel_indexed.rename(columns = {'Start': 'Start Year'})#.fillna(0)\n",
    "\n",
    "# filter years for blanks and not found values, replace these with 2028 as a placeholder\n",
    "steel_clean['Start Year'] = steel_clean['Start Year'].replace(to_replace = ['NA', ' ', '', np.nan, 0], value = '2027')\n",
    "\n",
    "# remove '(anticipated)' tag from the years in steel, clean years by taking only the last four digits\n",
    "clean_yrs = []\n",
    "for yr in steel_clean['Start Year']:\n",
    "    clean_yrs.append(float(yr[:4]))\n",
    "\n",
    "# add the years without this tag to the yr column\n",
    "steel_clean['Start Year'] = clean_yrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-familiar",
   "metadata": {},
   "source": [
    "### Create an output matrix which for weighting the steel data, including:\n",
    "- utilization capacity for each production type\n",
    "- emissions intensity for each production type\n",
    "- every country\n",
    "\n",
    "It should at the country level so that we can assume utilization and emissions intensity might vary locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code creates an output matrix propograted with arbitrary weights\n",
    "\n",
    "# utilization_rate_cols = []\n",
    "# emit_int_cols = []\n",
    "# for prod_type in production_cols:\n",
    "#     utilization_rate_cols.append(prod_type)\n",
    "#     emit_int_cols.append(prod_type)\n",
    "    \n",
    "# utilization_rate_df = pd.DataFrame(index = steel_clean['Country'].unique(), columns = utilization_rate_cols).fillna(1)\n",
    "# emit_int_df = pd.DataFrame(index = steel_clean['Country'].unique(), columns = emit_int_cols).fillna(1)\n",
    "\n",
    "# utilization_rate_df = utilization_rate_df.reset_index().rename(columns = {'index': 'country'})\n",
    "# emit_int_df = emit_int_df.reset_index().rename(columns = {'index': 'country'})\n",
    "\n",
    "# utilization_rate_df.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/steel_data/steel_country_UR_prod.csv')\n",
    "# emit_int_df.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/steel_data/steel_country_EI_prod.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-instrument",
   "metadata": {},
   "source": [
    "### Import locally modified versions of the steel weighting files\n",
    "- each df weighting file has a copy made of it locally, which gets modified and has another name\n",
    "- after being locally adjusted to reflect weighting differences by country, that file is imported again here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import the weighted data output by Tom. This is versions of what was output above modified to include\n",
    "# our priors on industry/steel emissions. See detailed estimates here: https://docs.google.com/spreadsheets/d/1TOH_Xq8rIaLiOM_cr0IwZuX5jw6KlRkpv2sJQSciHoc/edit?usp=sharing\n",
    "\n",
    "# Data in tonnes CO2 / tonne steel\n",
    "emit_int_weight = pd.read_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/steel_data/EMIT_INT_WEIGHTS.csv', index_col = 0)\n",
    "utr_rate_weight = pd.read_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/steel_data/UTILIZATION_RT_WEIGHTS.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-kingdom",
   "metadata": {},
   "source": [
    "### Weight steel data by emit int and utilization capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(utr_rate_weight) == len(emit_int_weight)\n",
    "\n",
    "# Converting data units from thousand tonnes steel/yr [aka (1/1000)(tonnes CO2/yr)] to (tonnes CO2/yr)\n",
    "# data/1000 = tonnes steel / per year\n",
    "steel_clean.iloc[:,4:] = steel_clean.iloc[:,4:] * 1000\n",
    "\n",
    "# Convert emissions intensity units from tonnes CO2/tonne steel to Mt CO2/tonne steel\n",
    "# emit_int/1000 = (tonne CO2/tonne Steel) /1000 = Mt CO2 / tonne steel\n",
    "emit_int_weight_mt = emit_int_weight / 1000\n",
    "\n",
    "# create a weighting factor by multiplying together the emissions intensity values and the utilization rates\n",
    "# this multiplies steel prod data in tonnes by an emit int in Mt CO2 / tonne steel, yielding Mt CO2\n",
    "weight_factor = pd.DataFrame(utr_rate_weight.iloc[1:,:].values * emit_int_weight_mt.iloc[1:,:].values)\n",
    "weight_factor['country.name.en'] = emit_int_weight_mt.index[1:]\n",
    "\n",
    "# merge the weighting factors and the data based on country, so every plant in a country gets weighted\n",
    "merged = steel_clean.merge(weight_factor)\n",
    "\n",
    "# make a new df from the weighted data, and give it proper columns, formatting, etc.\n",
    "weighted_steel_data = pd.DataFrame(data = merged.iloc[:,5:16].values * merged.iloc[:,16:].values)\n",
    "weighted_steel_data.columns = merged.iloc[:,5:16].columns\n",
    "weighted_steel_data[['country.name.en', 'Status', 'Start Year','Primary steelmaking process (integrated, electric, or oxygen)']] = steel_clean[['country.name.en', 'Status', 'Start Year','Primary steelmaking process (integrated, electric, or oxygen)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-customs",
   "metadata": {},
   "source": [
    "### Merge Weighted Steel Data with Country mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-representation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steel_merged = weighted_steel_data.rename(columns = {'country.name.en':'country'})\n",
    "\n",
    "# Make the column dtypes numeric, so that they add during the merge instead of concatenating as strings\n",
    "steel_merged['Start Year'] = steel_merged['Start Year'].astype(int).astype(str)\n",
    "\n",
    "# Group the data by the indices which will be used for row and column indices: country, status, and start.\n",
    "steel_pivot = steel_merged.pivot_table(index = 'country', columns = ['Status', 'Start Year']).sort_values('Start Year', axis = 1, ascending = True).fillna(0).groupby(by = ['Status','Start Year'], axis =1).sum()\n",
    "\n",
    "# Combine the multi-index pivot tables into panel data with standardized column names by reassigning\n",
    "# an adapted version of the column names to the data with .map()\n",
    "reset_steel = steel_pivot.reset_index()\n",
    "reset_steel.columns = reset_steel.columns.map('.'.join).str.strip('.')\n",
    "\n",
    "# Rename columns for R\n",
    "reset_steel.columns = ['steel.' + 'cap.' + str(col) for col in reset_steel.columns]\n",
    "steel_panel = reset_steel.rename(columns = {'steel.cap.country': 'country'})\n",
    "\n",
    "# Now in units of Mt CO2\n",
    "steel_panel.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/steel_data/steel_panel_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
