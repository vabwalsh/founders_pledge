{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = pd.read_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/scenario_credences/scenario.credences.csv', index_col = 0)\n",
    "\n",
    "# Create the probability weighted totals for affectability AND raw datasets\n",
    "affectable = pd.read_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/affectability_data/all_countries_emit_weighted_by_affectability.csv', index_col = 0)\n",
    "raw = pd.read_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/master_file/affectable_emissions_MASTER.csv', index_col = 0)\n",
    "\n",
    "# example files for plot testing\n",
    "ex_good = pd.read_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/scenario_credences/scenario.credencesEXTREME_GOOD.csv', index_col = 0)\n",
    "ex_bad = pd.read_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/scenario_credences/scenario.credencesEXTREME_BAD.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expectation_over_data(data, credence, area):\n",
    "    # make a column in the data data which will match the creedences data, merge on this column\n",
    "    clean_rcp = data['RCP'].str.replace('.', '')\n",
    "    data['cred_scen_match'] = data['SSP'] + '-' + clean_rcp\n",
    "    data['cred_scen_match'] = data['cred_scen_match'].str.replace('BL', 'Baseline')\n",
    "\n",
    "    scen_and_prob = data.merge(credence, left_on = 'cred_scen_match', right_on = 'scenario', how = 'inner').fillna(0)\n",
    "    sort_scen_prob = scen_and_prob.sort_values(by = 'country').reset_index().drop(columns = 'index')\n",
    "\n",
    "    # make a copy of the merged data in order to weight it\n",
    "    scen_and_prob_weighted = sort_scen_prob.copy()\n",
    "\n",
    "    # Multiply every emissions value in the dataset by it's affectability, converting the data to affectable emissions\n",
    "\n",
    "    # make active cols which should be weighted separate variable, matters b/c prob vars shouldn't be included\n",
    "    # in final output or get weighted by the following calculation\n",
    "    prob_cols_to_ignore = ['country', 'region', 'SSP', 'RCP', 'cred_scen_match','scenario','credence','posterior','p']\n",
    "\n",
    "    # multiply each row of emissions (but not p itself) in the merged dataset of global emissions \n",
    "    # by its data's p value\n",
    "    for col in scen_and_prob_weighted:\n",
    "        if col not in prob_cols_to_ignore:\n",
    "            scen_and_prob_weighted[col] = scen_and_prob_weighted[col] * scen_and_prob_weighted['p']\n",
    "\n",
    "    expectation = scen_and_prob_weighted.groupby(by = area).agg(np.nansum).reset_index()\n",
    "    return(expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_goodp = make_expectation_over_data(raw, ex_good, 'region')\n",
    "ex_badp = make_expectation_over_data(raw, ex_bad, 'region')\n",
    "\n",
    "ex_goodp.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/p_weighted_ex_good.csv')\n",
    "ex_badp.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/p_weighted_ex_bad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation_affectable = make_expectation_over_data(affectable, cred, 'country') \n",
    "expectation_raw = make_expectation_over_data(raw, cred, 'country')\n",
    "expectation_affectableRegion = make_expectation_over_data(affectable, cred, 'region') \n",
    "expectation_rawRegion = make_expectation_over_data(raw, cred, 'region')\n",
    "\n",
    "expectation_affectable.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/p_weighted_scen_all_countries_regionsAFFECTABLE.csv')\n",
    "expectation_raw.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/p_weighted_scen_all_countries_regionsRAW.csv')\n",
    "\n",
    "expectation_affectableRegion.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/p_weighted_scen_all_regions_AFFECTABLE.csv')\n",
    "expectation_rawRegion.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/p_weighted_scen_all_regions_RAW.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
