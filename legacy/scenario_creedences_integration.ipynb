{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accepted-matthew",
   "metadata": {},
   "source": [
    "##### Needs to be refactored after data is available for more regions than just China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cred = pd.read_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/scenario_credences/scenario.credences.csv', index_col = 0)\n",
    "scenario = pd.read_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/affectability_data/emit_data_weighted_by_affectability.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rcp = scenario['RCP'].str.replace('.', '')\n",
    "cred['scenario'] = cred['scenario'].replace('Baseline', 'BL')\n",
    "\n",
    "# make a column in the scenario data which will match the creedences data, merge on this column\n",
    "scenario['cred_scen_match'] = scenario['SSP'] + '-' + clean_rcp\n",
    "scen_and_prob = scenario.merge(cred, left_on = 'cred_scen_match', right_on = 'scenario', how = 'inner').fillna(0)\n",
    "\n",
    "# make a copy of the merged data in order to weight it\n",
    "scen_and_prob_weighted = scen_and_prob.copy()\n",
    "\n",
    "# make active cols which should be weighted separate variable, matters b/c prob vars shouldn't be included\n",
    "# in final output or get weighted by the following calculation\n",
    "prob_cols_to_ignore = ['Country', 'SSP', 'RCP', 'cred_scen_match','scenario','credence','posterior','p']\n",
    "\n",
    "# multiply each row of emissions (but not p itself) in the merged dataset of global emissions \n",
    "# by its scenario's p value\n",
    "for col in scen_and_prob_weighted:\n",
    "    if col not in prob_cols_to_ignore:\n",
    "        scen_and_prob_weighted[col] = scen_and_prob_weighted[col] * scen_and_prob_weighted['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scen_and_prob_weighted # want the SUM of these columns to have expected value of emits for a region\n",
    "# scen_and_prob # these are meaningful: they describe diff descrete potential worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the prob cols to avoid annoying indexing issues\n",
    "scen_and_prob_weighted = scen_and_prob_weighted.drop(columns = ['cred_scen_match','scenario','credence','posterior','p'])\n",
    "\n",
    "# calculate the last row of the whole DF, the global total of probability expected emissions for each year\n",
    "# start at column 4, since the first three are country/rcp/ssp\n",
    "global_totals = np.nansum(scen_and_prob_weighted.iloc[:,3:], axis = 0)\n",
    "\n",
    "# add the appropriate \"region\", ssp, and rcp to the totals from each emission column\n",
    "global_totals_row = ['Global','SSPtotal','RCPtotal'] + list(global_totals)\n",
    "\n",
    "# male a dataframe from this list\n",
    "global_expected = pd.DataFrame(global_totals_row).transpose()\n",
    "\n",
    "# make the columns here the same as those from the emit df\n",
    "global_expected.columns = scen_and_prob_weighted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code creates a row in the df where all the data from a given region is summed by column, the\n",
    "# next cell appends that to the existing df. This cell can be uncommented where data is available for \n",
    "# more countries than China, and region mappings have been either explicitly included or added to the df.\n",
    "\n",
    "# region_rows = []\n",
    "# for region in scen_and_prob_weighted['region'].unique():\n",
    "#     region_row_sum = np.nansum(scen_and_prob_weighted[scen_and_prob_weighted['region'] == region].iloc[:,3:819], axis = 0)\n",
    "#     region_row_sum = [region] + ['SSPtotal'] + ['RCPtotal'] + list(region_row_sum)\n",
    "#     region_rows.append(region_row_sum)\n",
    "\n",
    "# region_expected = pd.DataFrame(region_rows, columns = scen_and_prob_weighted.columns[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the newly derived totals for regions and overall to the orginal (non-weighted) data\n",
    "all_data = scen_and_prob.append(global_expected)\n",
    "#uncomment with cell above: all_data = all_data.append(region_expected)\n",
    "\n",
    "p = all_data.pop('p')\n",
    "all_data.insert(3, 'p', p)\n",
    "\n",
    "final = all_data.iloc[:,:-4].reset_index().drop(columns = 'index')\n",
    "final.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/p_weighted_scen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_split = cred['scenario'].str.split('-')\n",
    "arr = cred_split.apply(pd.Series).values\n",
    "SSPs = arr[:,0]\n",
    "RCPs = np.char.replace(arr[:,1].astype(str), 'Baseline', 'BL')\n",
    "\n",
    "rcp_dot = []\n",
    "for rcp in RCPs:\n",
    "    if 'BL' not in rcp:\n",
    "        rcp = '.'.join(rcp)\n",
    "        rcp_dot.append(rcp)\n",
    "    elif 'BL' in rcp:\n",
    "        rcp_dot.append(rcp)\n",
    "        \n",
    "output = pd.DataFrame(columns = ['credences.scenario', 'emit.data.scenario.SSP', 'emit.data.scenario.RCP'])\n",
    "output['credences.scenario'] = cred['scenario']\n",
    "output['emit.data.scenario.SSP'] = SSPs\n",
    "output['emit.data.scenario.RCP'] = rcp_dot\n",
    "output.to_csv('~/Desktop/Founders_Pledge/affectable_emissions_active_repo/Affectable-Emissions/data_files/affectability_scenarios_match.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
